import sys, os
sys.path.insert(0, os.path.abspath(os.curdir))

from dotenv import load_dotenv
from langchain.chat_models import AzureChatOpenAI, ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

load_dotenv()

def openAIstage2(user_last_messages):
    chat = AzureChatOpenAI(
        openai_api_base=os.getenv("OPENAI_API_BASE"),
        openai_api_version="2023-05-15",
        deployment_name="gpt-35-turbo",
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        openai_api_type="azure",
        temperature=0.4
    )

    #chat = ChatOpenAI(
    #    openai_api_key=os.getenv("OPENAI_API_KEY"),
    #    model='gpt-3.5-turbo'
    #)

    content = f"""Baseando-se na resposta do lead, voc√™ precisa sugerir se devemos prosseguir com a conversa ou n√£o.
        Resposta do lead: {user_last_messages}

        Exemplos de resposta no formato json:
        {{
            'Mensagem do lead': üëç,
            'Acao': 'Aceitar'
        }}

        {{
            'Mensagem do lead': 'Sim',
            'Acao': 'Aceitar'
        }}

        {{
            'Mensagem do lead': 'N√£o',
            'Acao': 'Rejeitar'
        }}
    """

    gpt_prompt = [
        SystemMessage(content="""Voc√™ analisa conversas com poss√≠veis clientes de um servi√ßo de intelig√™ncia artificial que 
        cria documentos para advogados. A sua responsabilidade √© avaliar se devemos prosseguir com a conversa dependendo do 
        interesse demonstrado na resposta."""),
        HumanMessage(content=content)
    ]

    gpt_answer = chat(gpt_prompt).content

    return gpt_answer